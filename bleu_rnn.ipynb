{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKKWNtE7LNRq",
        "outputId": "091ff07c-5526-4f59-d7ac-d3f2868ac5ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/translate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOGHhUAVLm7M",
        "outputId": "93abd355-24dd-428f-a4e3-4ade089127bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LKdsji4MDYv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "from sacrebleu import BLEU\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yOYmI84LxPr"
      },
      "outputs": [],
      "source": [
        "def load_text_vectorization(path):\n",
        "    from_disk = pickle.load(open(path, \"rb\"))\n",
        "    tv = tf.keras.layers.TextVectorization.from_config(from_disk['config'])\n",
        "    tv.set_weights(from_disk['weights'])\n",
        "    return tv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLggFvd0N4l_"
      },
      "outputs": [],
      "source": [
        "bleu = BLEU()\n",
        "import os\n",
        "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
        "\n",
        "model_name = 'LSTM_PTT_2023_08_06_VS20000_SL20_Fri_Aug_11_185708_2023.keras'\n",
        "split_char = '⫯'\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "tv_name = 'PTT_2023_08_06'\n",
        "source_vectorization = load_text_vectorization(f\"models/{tv_name}_source_vectorization.pkl\")\n",
        "target_vectorization = load_text_vectorization(f\"models/{tv_name}_target_vectorization.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBllXkblN-zf"
      },
      "outputs": [],
      "source": [
        "zh_vocab = target_vectorization.get_vocabulary()\n",
        "zh_index_lookup = dict(zip(range(len(zh_vocab)), zh_vocab))\n",
        "model = tf.keras.models.load_model(f'models/{model_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mqE6RuoNxWV"
      },
      "outputs": [],
      "source": [
        "with open(f'datasets/{tv_name}_engTyping_inserted_lines.txt', encoding='utf8') as file:\n",
        "    engTyping_inserted_lines = file.readlines()\n",
        "with open(f'datasets/{tv_name}_zh_lines.txt', encoding='utf8') as file:\n",
        "    zh_lines = file.readlines()\n",
        "lines_len = len(engTyping_inserted_lines)\n",
        "assert lines_len == len(zh_lines)\n",
        "engTyping_inserted_lines = engTyping_inserted_lines[int(lines_len * 0.85):]\n",
        "zh_lines = zh_lines[int(lines_len * 0.85):]\n",
        "for i in range(len(zh_lines)):\n",
        "    zh_lines[i] = ' '.join(zh_lines[i].split(split_char)[1:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuX5AiD_K2Fj",
        "outputId": "4e625040-ebd6-4818-f1dd-e52a09fa63f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199/200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred_sentences = []\n",
        "loop_times = 200\n",
        "eng_len = len(engTyping_inserted_lines)\n",
        "split_point = eng_len // loop_times\n",
        "for k in range(loop_times + 1):\n",
        "    lines = engTyping_inserted_lines[k * split_point:(k + 1) * split_point]\n",
        "    len_lines = len(lines)\n",
        "    tokenized_input_sentence = source_vectorization(lines)\n",
        "    decoded_sentences = [\"[start]\"] * len_lines\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            decoded_sentences)[:, :-1]\n",
        "        predictions = model(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        for j in range(len_lines):\n",
        "            if decoded_sentences[j].endswith('[end]'): continue\n",
        "            decoded_sentences[j] += split_char + zh_index_lookup[np.argmax(predictions[j, i, :])]\n",
        "    pred_sentences.extend(decoded_sentences)\n",
        "    print(f'\\r{k}/{loop_times}', end='')\n",
        "\n",
        "\n",
        "print(pred_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnyz6PTLOHAf",
        "outputId": "1b41a37d-4a78-4d63-8089-51bbe9d18f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU = 78.56 86.6/81.8/77.3/73.0 (BP = 0.988 ratio = 0.988 hyp_len = 2874646 ref_len = 2909826)\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for i in range(len(pred_sentences)):\n",
        "    pred_sentences[i] = pred_sentences[i][7:]\n",
        "    if pred_sentences[i].endswith('[end]'): pred_sentences[i] = pred_sentences[i][:-5]\n",
        "    pred_sentences[i] = pred_sentences[i].replace(split_char, ' ')\n",
        "    count += 1\n",
        "    print(f'{count}/{eng_len}', end='\\r')\n",
        "\n",
        "result = bleu.corpus_score(pred_sentences, [zh_lines])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB4X3PjZOGaZ",
        "outputId": "aba45e9f-e298-4f41-f74b-b9f6c9db209c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231813"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(pred_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzPt8UyHOTzV",
        "outputId": "30a5cf05-7b6e-4cc1-d748-871f3c9fc764"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231813"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(zh_lines)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}