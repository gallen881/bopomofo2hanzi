{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO6N5rPKfCgw"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy59OTtb6Fjn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# import os\n",
        "# os.chdir('/content/drive/My Drive/translate')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install rar"
      ],
      "metadata": {
        "id": "VYEjq_MCeenr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rar x datasets.rar"
      ],
      "metadata": {
        "id": "EC3W615OjEE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqIXBUCS6OL1"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate sacrebleu nltk keras_nlp\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6BZk-9Z4aQ0"
      },
      "outputs": [],
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "from transformers import TFAutoModelForSeq2SeqLM\n",
        "from transformers import AdamWeightDecay\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import AutoTokenizer\n",
        "import datasets\n",
        "import tensorflow as tf\n",
        "# import keras_nlp\n",
        "# from nltk.translate.bleu_score import sentence_bleu\n",
        "# import evaluate\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZITxfx-4kiv"
      },
      "outputs": [],
      "source": [
        "split_char = 'â«¯'\n",
        "data_name = 'PTT_2023_08_06'\n",
        "model_name = f'mT5_small_PTT_2023_08_06_Thu_Aug_17_081645_2023.ckpt'\n",
        "# model_name = f'mT5_small_{data_name}_{time.ctime().replace(\" \", \"_\").replace(\":\", \"\")}.ckpt'\n",
        "checkpoint = \"google/mt5-small\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "991cHkgKtT4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"translate engTyping to Traditional Chinese:\".split()"
      ],
      "metadata": {
        "id": "JkvUVM4Zn-9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEWezNd44lPd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "with open(f'datasets/{data_name}_engTyping_inserted_lines.txt', 'r', encoding='utf-8') as file:\n",
        "    engTyping_inserted_lines = file.readlines()\n",
        "with open(f'datasets/{data_name}_zh_lines.txt', 'r', encoding='utf-8') as file:\n",
        "    zh_lines = file.readlines()\n",
        "\n",
        "engTyping_inserted_lines = [prefix + line.split(split_char) for line in engTyping_inserted_lines]\n",
        "lines_len = len(engTyping_inserted_lines)\n",
        "train_engTyping_inserted_lines = engTyping_inserted_lines[:int(lines_len * 0.7)]\n",
        "val_engTyping_inserted_lines = engTyping_inserted_lines[int(lines_len * 0.7):int(lines_len * 0.85)]\n",
        "test_engTyping_inserted_lines = engTyping_inserted_lines[int(lines_len * 0.85):]\n",
        "zh_lines = [line.split(split_char)[1:-1] for line in zh_lines]\n",
        "lines_len = len(zh_lines)\n",
        "train_zh_lines = zh_lines[:int(lines_len * 0.7)]\n",
        "val_zh_lines = zh_lines[int(lines_len * 0.7):int(lines_len * 0.85)]\n",
        "test_zh_lines = zh_lines[int(lines_len * 0.85):]\n",
        "assert len(train_engTyping_inserted_lines) == len(train_zh_lines)\n",
        "assert len(val_engTyping_inserted_lines) == len(val_zh_lines)\n",
        "assert len(test_engTyping_inserted_lines) == len(test_zh_lines)\n",
        "train_lines = tokenizer(train_engTyping_inserted_lines, text_target=train_zh_lines, max_length=128, is_split_into_words=True, truncation=True)\n",
        "val_lines = tokenizer(val_engTyping_inserted_lines, text_target=val_zh_lines, max_length=128, is_split_into_words=True, truncation=True)\n",
        "test_lines = tokenizer(test_engTyping_inserted_lines, text_target=test_zh_lines, max_length=128, is_split_into_words=True, truncation=True)\n",
        "\n",
        "train_dataset = datasets.Dataset.from_dict(train_lines)\n",
        "val_dataset = datasets.Dataset.from_dict(val_lines)\n",
        "test_dataset = datasets.Dataset.from_dict(test_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwlEOfPyA7pD"
      },
      "outputs": [],
      "source": [
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('models/mT5_small_PTT_2023_08_06_Thu_Aug_17_081645_2023.ckpt')"
      ],
      "metadata": {
        "id": "EWF5gHsKYk_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
      ],
      "metadata": {
        "id": "poQuv6JatPMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL03LOUi4rlY"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint, return_tensors=\"tf\")\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    # dataset[\"train\"],\n",
        "    train_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_val_set = model.prepare_tf_dataset(\n",
        "    # dataset[\"validation\"],\n",
        "    val_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_test_set = model.prepare_tf_dataset(\n",
        "    # dataset[\"validation\"],\n",
        "    test_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg2Ys4iZBI92"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.debugging.disable_traceback_filtering()"
      ],
      "metadata": {
        "id": "aEAjix-uSVaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self, tokenizer, name=\"bleu\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bleu = sentence_bleu\n",
        "        self.bleu_score = self.add_weight(\n",
        "            shape=(),\n",
        "            initializer='zeros',\n",
        "            dtype=self.dtype,\n",
        "            name = 'bleu_score'\n",
        "        )\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # print(dir(y_true))\n",
        "        # print(dir(y_pred))\n",
        "        # print(y_true.value_index)\n",
        "        # print(y_pred.value_index)\n",
        "        # print(y_true[2])\n",
        "        # print(y_pred[0])\n",
        "        # print(dir(y_true[2]))\n",
        "        # print(dir(y_pred[0]))\n",
        "        # print(y_true[2].value_index)\n",
        "        # print(y_pred[0].value_index)\n",
        "        # print(y_true[2][0])\n",
        "        # print(y_pred[0][0])\n",
        "        # print(y_true[2][0][0])\n",
        "        # print(y_pred[0][0][0])\n",
        "        # decoded_pred = self.tokenizer.batch_decode(y_pred, skip_special_tokens=True)\n",
        "        # y_true = np.where(y_true != -100, y_true, tokenizer.pad_token_id)\n",
        "        # decoded_true = self.tokenizer.batch_decode(y_true, skip_special_tokens=True)\n",
        "        # decoded_pred, decoded_true = postprocess_text(decoded_pred, decoded_true)\n",
        "        result = self.bleu(y_true, y_pred)\n",
        "        self.bleu_score.assign(result)\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.bleu_score.assign(0.0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"tokenizer\": self.tokenizer,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "HnrFwtSBM3wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVfJ4VgP5xIk"
      },
      "outputs": [],
      "source": [
        "tf_train_set.save(f'datasets/mT5_{data_name}_tf_train_dataset.tfrecord')\n",
        "tf_val_set.save(f'datasets/mT5_{data_name}_tf_val_dataset.tfrecord')\n",
        "# tf_test_set.save(f'datasets/mT5_{data_name}_tf_test_dataset.tfrecord')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbC9afFE5xzt"
      },
      "outputs": [],
      "source": [
        "tf_train_set = tf.data.Dataset.load(f'datasets/mT5_{data_name}_tf_train_dataset.tfrecord')\n",
        "tf_val_set = tf.data.Dataset.load(f'datasets/mT5_{data_name}_tf_val_dataset.tfrecord')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('../../../.')"
      ],
      "metadata": {
        "id": "MAOLId2pYanL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "metadata": {
        "id": "7hLRmryRYo64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "4uF1yKN_XrQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "ykQKo6Qwc96f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9AuwNXL50kT"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer, metrics=[\"accuracy\"])  # No loss argument!\n",
        "\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_val_set)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(f'models/{model_name}',save_best_only=True, save_weights_only=True),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=f'logs/{model_name}_logs')\n",
        "]\n",
        "\n",
        "model.fit(x=tf_train_set, validation_data=tf_val_set, epochs=1, callbacks=callbacks)\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('/content/drive/My Drive/translate')\n",
        "model.save_pretrained(f'models/{model_name}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, 'model.png')"
      ],
      "metadata": {
        "id": "ghs5qFDqKxUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(f'models/{model_name}', save_format='tf')"
      ],
      "metadata": {
        "id": "90LKzOxK5AdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_char = 'â«¯'\n",
        "punctuations = 'ãï¼ãï¼ï¼ï¼ï¼'\n",
        "\n",
        "def engTyping_insert_split_char(sentence: str, split_char: str) -> str:\n",
        "    insert_times = 0\n",
        "    sentence_list = list(sentence)\n",
        "    for i, char in enumerate(sentence):\n",
        "        if char in ' 6347' + punctuations:\n",
        "            sentence_list.insert(i + insert_times + 1, split_char)\n",
        "            insert_times += 1\n",
        "    return ''.join(sentence_list[:-1])"
      ],
      "metadata": {
        "id": "cBRwgyZzrano"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy948uP755ey"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(prefix + engTyping_insert_split_char(input('?:'), split_char).split(split_char), is_split_into_words=True, return_tensors=\"tf\", truncation=True).input_ids\n",
        "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}